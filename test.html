<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>AR Testing</title>
    
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/donmccurdy/aframe-extras@v7.0.0/dist/aframe-extras.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>

    <style>
      html, body {
        margin: 0;
        padding: 0;
        height: 100%;
        overflow: hidden;
        font-family: sans-serif;
      }

      #start-overlay {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-color: black;
        color: white;
        z-index: 999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
      }

      #start-button {
        padding: 14px 28px;
        font-size: 16px;
        background-color: #00cec9;
        color: white;
        border: none;
        border-radius: 6px;
        cursor: pointer;
        margin-top: 12px;
      }

      #rec-controls{
        position:fixed;
        bottom:12px;
        left:12px;
        z-index:9999;
        display:flex;
        gap:8px;
        align-items:center;
        font-family:sans-serif
      }
      
      #rec-toggle{
        padding:10px 14px;
        border:0;
        border-radius:6px;
        background:#e63946;
        color:#fff
      }
      
      #dl{
        background:#0a7; 
        color:#fff; 
        padding:8px 12px; 
        border-radius:6px; 
        text-decoration:none; 
        display:none
      }
      #mic-label{
        background:#000a;
        color:#fff;
        padding:6px 8px;
        border-radius:6px
      }
    </style>
  </head>

  <body>
    <!-- üëÜ Tap-to-start overlay -->
    <div id="start-overlay">
      <h1>Tap to Start AR Experience</h1>
      <button id="start-button">Start</button>
    </div>

    <div id="rec-controls">
      <button id="rec-toggle">‚óè Start Recording</button>
      <label id="mic-label"><input id="include-mic" type="checkbox"> Include mic</label>
      <a id="dl" download>Download</a>
    </div>

    <!-- ‚úÖ A-Frame Scene (Never hidden!) -->
    <a-scene
      mindar-image="imageTargetSrc: ./targets.mind; autoStart: true; uiScanning: true; uiLoading: true;"
      embedded
      color-space="sRGB"
      renderer="colorManagement: true, physicallyCorrectLights"
      vr-mode-ui="enabled: false"
      device-orientation-permission-ui="enabled: true"
      id="ar-scene"
    >
      <a-assets>
        <video
          id="ad-video"
          src="./video.mp4"
          preload="auto"
          crossorigin="anonymous"
          playsinline
          webkit-playsinline
          controls
        ></video>
      </a-assets>

      <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

      <a-entity mindar-image-target="targetIndex: 0" id="video-target">
        <a-video
          id="video-plane"
          src="#ad-video"
          width="1"
          height="1.5"
          position="0 0 0"
          rotation="0 0 0"
        ></a-video>
      </a-entity>
    </a-scene>

    <script>
      const startButton = document.getElementById("start-button");
      const overlay = document.getElementById("start-overlay");
      const video = document.getElementById("ad-video");
      const target = document.getElementById("video-target");

      let audioUnlocked = false;

      startButton.addEventListener("click", async () => {
        // Unlock video/audio on user gesture
        try {
          await video.play();
        } catch (e) {
          console.warn("Autoplay failed (expected), will retry later.");
        }
        video.pause();
        audioUnlocked = true;

        // Hide overlay
        overlay.style.display = "none";
      });

      target.addEventListener("targetFound", () => {
        console.log("üîç Marker detected");
        if (audioUnlocked) {
          video.play();
        }
      });

      target.addEventListener("targetLost", () => {
        console.log("üîç Marker lost");
        video.pause();
      });

      const sceneEl   = document.querySelector('a-scene');
      const recBtn    = document.getElementById('rec-toggle');
      const dl        = document.getElementById('dl');
      const micBox    = document.getElementById('include-mic');
      const videoEl   = document.getElementById('ad-video');
    
      let mediaRecorder, chunks = [], audioCtx, dest, micStream, recording = false;
    
      function pickMime() {
        // iOS Safari prefers mp4, others often webm
        if (MediaRecorder.isTypeSupported('video/mp4')) return 'video/mp4';
        if (MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus')) return 'video/webm;codecs=vp9,opus';
        return 'video/webm';
      }
    
      async function setupRecorder() {
        // Wait until A-Frame‚Äôs WebGL canvas exists
        const canvas = sceneEl.canvas;
        if (!canvas) { console.warn('A-Frame canvas not ready yet'); return; }
    
        // 1) Video track = AR render (camera + overlays) via canvas.captureStream()
        //    (works on modern Safari/Chrome ‚Äì record exactly what user sees)
        const canvasStream = canvas.captureStream(30); // target 30fps
        const videoTrack   = canvasStream.getVideoTracks()[0];
    
        // 2) Build an audio mix (video‚Äôs audio + optional mic) via Web Audio
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        dest     = audioCtx.createMediaStreamDestination();
    
        // Route the <video> element‚Äôs audio into the mix
        const videoSrc = audioCtx.createMediaElementSource(videoEl);
        videoSrc.connect(dest);      // to recorder
        videoSrc.connect(audioCtx.destination); // to device speakers (optional)
    
        // Optional mic on demand
        if (micBox.checked) {
          micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          const micSrc = audioCtx.createMediaStreamSource(micStream);
          micSrc.connect(dest);
        }
    
        // 3) Combine AR video + mixed audio into one MediaStream
        const mixedStream = new MediaStream([videoTrack, ...dest.stream.getAudioTracks()]);
    
        // 4) Create MediaRecorder
        mediaRecorder = new MediaRecorder(mixedStream, {
          mimeType: pickMime(),
          videoBitsPerSecond: 4_000_000
        });
    
        mediaRecorder.ondataavailable = (e) => { if (e.data && e.data.size) chunks.push(e.data); };
        mediaRecorder.onstop = () => {
          const type = mediaRecorder.mimeType || 'video/webm';
          const blob = new Blob(chunks, { type });
          chunks = [];
          const url = URL.createObjectURL(blob);
          dl.href = url;
          dl.download = /mp4/.test(type) ? 'ar-capture.mp4' : 'ar-capture.webm';
          dl.style.display = 'inline-block';
          recBtn.textContent = '‚óè Start Recording';
          recording = false;
        };
      }
    
      // Ensure we set up after the scene is ready
      sceneEl.addEventListener('loaded', setupRecorder);
    
      recBtn.addEventListener('click', async () => {
        // User gesture: resume AudioContext for iOS Safari
        if (audioCtx && audioCtx.state === 'suspended') await audioCtx.resume();
    
        if (!mediaRecorder) await setupRecorder();
    
        if (!recording) {
          dl.style.display = 'none';
          mediaRecorder.start(); // start capturing
          recBtn.textContent = '‚ñ† Stop Recording';
          recording = true;
        } else {
          mediaRecorder.stop();
          if (micStream) micStream.getTracks().forEach(t => t.stop());
        }
      });
    </script>
  </body>
</html>
